{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Install KenLM**\n",
        "Read [this](https://kheafield.com/code/kenlm/) for more info "
      ],
      "metadata": {
        "id": "rzvN8Xj0xn3S"
      },
      "id": "rzvN8Xj0xn3S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33c1443b",
      "metadata": {
        "id": "33c1443b",
        "outputId": "eb97e448-acd5-438c-a72e-a44f075663ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kenlm' already exists and is not an empty directory.\n",
            "/home/sadeghi/Notebooks/kenlm\n",
            "/home/sadeghi/Notebooks/kenlm/build\n",
            "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /home/sadeghi/Notebooks/kenlm/build\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target kenlm_util\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-conversion.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
            "[ 38%] Built target kenlm_util\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target probing_hash_table_benchmark\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
            "[ 41%] Built target probing_hash_table_benchmark\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target kenlm\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
            "[ 66%] Built target kenlm\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target query\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
            "[ 68%] Built target query\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target fragment\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
            "^C\n",
            "make[2]: *** [lm/CMakeFiles/fragment.dir/build.make:76: lm/CMakeFiles/fragment.dir/fragment_main.cc.o] Interrupt\n",
            "make[1]: *** [CMakeFiles/Makefile2:346: lm/CMakeFiles/fragment.dir/all] Interrupt\n",
            "make: *** [Makefile:136: all] Interrupt\n",
            "/home/sadeghi/Notebooks\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kpu/kenlm.git\n",
        "%cd kenlm\n",
        "!mkdir -p build\n",
        "%cd build\n",
        "!cmake .. && make\n",
        "%cd ../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0892a518",
      "metadata": {
        "id": "0892a518"
      },
      "outputs": [],
      "source": [
        "import kenlm\n",
        "from pyctcdecode import build_ctcdecoder\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Make Language Model using KenLM**\n",
        "In this section, we used cleaned, normalized, and processed Farsi text data to prepare a language model. It is better to use large-size text data and diverse in terms of structure and classification, which means that the data includes poetry, news, daily conversation, etc.\n",
        "\n",
        "We have written a comprehensive data-cleaning program that I will add to the documentation.\n",
        "KenLM also has some configurations such as `prune`.\n",
        "\n",
        "using these options make your LM lighter and faster, improves your performance"
      ],
      "metadata": {
        "id": "m1ACbHEiyRiR"
      },
      "id": "m1ACbHEiyRiR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce33bba6",
      "metadata": {
        "scrolled": true,
        "id": "ce33bba6",
        "outputId": "b92c622b-9c24-479f-a9dd-e805d2074e52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /home/sadeghi/totalck_UTF8_clean.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# raw_text.txt: a normalized text corpus (each line should contain a sentence)\n",
        "!kenlm/build/bin/lmplz -o 5 \\\n",
        "    </home/sadeghi/totalck_UTF8_clean.txt \\\n",
        "    >/home/sadeghi/language_model_15G/5-gram.arpa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3826574",
      "metadata": {
        "id": "e3826574"
      },
      "outputs": [],
      "source": [
        "!kenlm/build/bin/build_binary \\\n",
        "    /home/sadeghi/language_model_15G/5-gram.arpa \\\n",
        "    /home/sadeghi/language_model_15G/5-gram.bin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section wraps the model processor with LM that you can use later to transcript more accurately."
      ],
      "metadata": {
        "id": "RhNy1tVl0l7b"
      },
      "id": "RhNy1tVl0l7b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c67ab273",
      "metadata": {
        "id": "c67ab273"
      },
      "outputs": [],
      "source": [
        "from pyctcdecode import build_ctcdecoder\n",
        "from transformers import AutoProcessor\n",
        "from transformers import Wav2Vec2ProcessorWithLM\n",
        "\n",
        "model_id = \"/home/sadeghi/New_training_all_data/chekpoint-318000\"\"\n",
        "\n",
        "# LM must be in arpa format (for now)\n",
        "lm_path = \"/home/sadeghi/language_model_15G/5-gram.arpa\"\n",
        "\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "vocab_dict = processor.tokenizer.get_vocab()\n",
        "sorted_dict = {k: v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
        "\n",
        "decoder = build_ctcdecoder(\n",
        "    list(sorted_dict.keys()),\n",
        "    lm_path,\n",
        ")\n",
        "\n",
        "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    decoder=decoder\n",
        ")\n",
        "\n",
        "processor_with_lm.save_pretrained(\"/home/sadeghi/language_model_15G/processor_with_lm_sadeghi\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
